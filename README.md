# <img src="screenshots/cmdai-logo.png" alt="cmdAI Logo" width="40" style="vertical-align: middle;"> cmdAI Terminal v1.0

> A familiar and easy to use terminal interface for OpenAI and/or Ollama

cmdAI Terminal brings the elegance of modern chat interfaces to your terminal, with a carefully crafted dark theme, real-time streaming, and intelligent conversation management. Works seamlessly with both Ollama and OpenAI models.

## ğŸ“¸ Screenshots

![cmdAI Terminal Main Interface](screenshots/tui.png)
*Main chat interface with sidebar navigation and streaming responses*

![Model Selection Screen](screenshots/tui-modelselection.png)
*Easy model switching with support for Ollama and OpenAI models*

---

## âœ¨ Features

### ğŸ¯ Core Experience
- ğŸ–¥ï¸ **Beautiful TUI** - Modern terminal interface built with Textual and custom cmdAI dark theme
- âš¡ **Real-time Streaming** - Watch AI responses appear token-by-token as they're generated
- ğŸ’¬ **Rich Markdown** - Full support for code blocks, tables, lists, headers, and more

### ğŸ”„ Conversation Management
- ğŸ“š **Persistent History** - All conversations automatically saved and resumable
- ğŸ—‚ï¸ **Quick Navigation** - Browse and switch between chats in the sidebar
- ğŸ—‘ï¸ **Smart Deletion** - Delete individual conversations (d) or clear all (Ctrl+D)
- ğŸ“ **Auto-titling** - First message becomes the conversation title

### ğŸ¤– Model Control
- ğŸ”€ **Instant Switching** - Click model name or press Ctrl+M to change models
- ğŸ¦™ **Ollama Support** - Full integration with local Ollama models
- â­ **OpenAI Support** - Connect to OpenAI's GPT models with API key
- ğŸ’¾ **Model Persistence** - Remembers your last selected model between sessions
- ğŸ“‹ **Dynamic Loading** - Automatically fetches available models from both providers

### âŒ¨ï¸ Developer Friendly
- âš¡ **Keyboard Shortcuts** - Efficient navigation without touching the mouse
- ğŸ¨ **Clean Minimalist UI** - Distraction-free interface with intuitive interactions
- ğŸ“ **Split-pane Layout** - Sidebar for navigation, main area for focused chatting

---

## ğŸš€ Quick Start

### Installation

```bash
# Quick install
pip install -e .

# Or install dependencies manually
pip install textual rich httpx pyyaml
```

### Configuration

Create `config.yaml` in your current directory or at `~/.cmdai-terminal/config.yaml`:

```yaml
api:
  ollama:
    base_url: http://localhost:11434  # Your Ollama API endpoint
    timeout: 60
  openai:
    api_key: sk-your-key-here  # Optional: Add your OpenAI API key
    timeout: 60

ui:
  theme: dark
  sidebar_width: 35

storage:
  conversations_dir: ~/.cmdai-terminal/conversations

default_model: llama2  # Your preferred model
```

**Note:** Both providers are optional - you can use:
- Only Ollama (leave `api_key: null`)
- Only OpenAI (Ollama endpoint doesn't need to be available)
- Both providers simultaneously for maximum flexibility

### Run It

```bash
cmdai-terminal

# Or if not installed as a package
python3 -m cmdai_terminal
```

---

## âŒ¨ï¸ Keyboard Shortcuts

| Key | Action | Description |
|-----|--------|-------------|
| **Ctrl+N** | New Chat | Start a fresh conversation |
| **Ctrl+M** | Change Model | Open model selector |
| **Ctrl+Q** | Quit | Exit the application |
| **Enter** | Send | Send your message |
| **Esc** | Cancel | Close dialogs/cancel actions |
| **d** | Delete | Delete selected conversation |
| **Ctrl+D** | Clear All | Delete all conversations |
| **â†‘/â†“** | Navigate | Browse conversations/options |

---

## ğŸ“ Project Structure

```
cmdai-terminal/
â”œâ”€â”€ ğŸ“„ pyproject.toml              # Project dependencies & metadata
â”œâ”€â”€ âš™ï¸ config.yaml                 # User configuration
â”œâ”€â”€ ğŸ“š cmdai_terminal/
â”‚   â”œâ”€â”€ ğŸš€ __main__.py            # Entry point
â”‚   â”œâ”€â”€ ğŸ¨ app.py                 # Main Textual application & UI
â”‚   â”œâ”€â”€ âš™ï¸ config.py              # Configuration management
â”‚   â”œâ”€â”€ ğŸŒ api/
â”‚   â”‚   â”œâ”€â”€ ollama.py             # Ollama API client & streaming
â”‚   â”‚   â”œâ”€â”€ openai_client.py      # OpenAI API client & streaming
â”‚   â”‚   â””â”€â”€ unified_client.py     # Unified client for both providers
â”‚   â”œâ”€â”€ ğŸ§© components/
â”‚   â”‚   â”œâ”€â”€ sidebar.py            # Sidebar navigation component
â”‚   â”‚   â”œâ”€â”€ chat_view.py          # Chat display with markdown
â”‚   â”‚   â””â”€â”€ input_box.py          # Message input component
â”‚   â”œâ”€â”€ ğŸ“¦ models/
â”‚   â”‚   â”œâ”€â”€ conversation.py       # Conversation data model
â”‚   â”‚   â””â”€â”€ message.py            # Message data model
â”‚   â””â”€â”€ ğŸ’¾ storage/
â”‚       â””â”€â”€ history.py            # Conversation persistence (JSON)
```

---

## ğŸ”Œ API Compatibility

cmdAI Terminal works with both **Ollama** and **OpenAI** API endpoints. More will be added asap, such as Claude, Gemini etc.

### Ollama API

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/tags` | GET | List available models |
| `/api/chat` | POST | Chat completions with streaming |

**Request Format:**
```json
{
  "model": "llama2",
  "messages": [
    {"role": "user", "content": "Hello!"},
    {"role": "assistant", "content": "Hi! How can I help?"}
  ],
  "stream": true
}
```

**Response Format:** NDJSON with `{"message": {"content": "token"}}`

### OpenAI API

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/v1/models` | GET | List available models |
| `/v1/chat/completions` | POST | Chat completions with streaming |

**Request Format:**
```json
{
  "model": "gpt-4o",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ],
  "stream": true
}
```

**Response Format:** SSE with `data: {"choices": [{"delta": {"content": "token"}}]}`

### Model Selection

- **Ollama models:** Display as `ğŸ¦™ model-name` (e.g., `ğŸ¦™ llama2`)
- **OpenAI models:** Display as `â­ openai/model-name` (e.g., `â­ openai/gpt-4o`)
- The app automatically routes to the correct provider based on model prefix

---

## ğŸ› Troubleshooting

### ğŸ”´ Cannot connect to Ollama API

**Symptoms:** Ollama models not loading

**Solutions:**
1. âœ… Verify your API is running: `curl http://localhost:11434/api/tags`
2. âœ… Check `config.yaml` has the correct `ollama.base_url`
3. âœ… Ensure firewall allows the connection
4. âœ… Try increasing the `timeout` value in config

### ğŸ”´ Cannot connect to OpenAI API

**Symptoms:** OpenAI models not loading or showing errors

**Solutions:**
1. âœ… Verify your API key is valid: Check at https://platform.openai.com/api-keys
2. âœ… Ensure `api_key` is set in `config.yaml` under `api.openai.api_key`
3. âœ… Check you have credits/quota available in your OpenAI account
4. âœ… Try increasing the `timeout` value in config

### ğŸ”´ Models not loading

**Symptoms:** Only seeing default model, no model list

**Solutions:**
1. âœ… Check both provider configurations in `config.yaml`
2. âœ… Verify at least one provider is properly configured
3. âœ… App will use fallback models if both APIs are unavailable
4. âœ… Look for error messages in the terminal output

### ğŸ”´ Conversations not saving

**Symptoms:** Chats disappear after closing app

**Solutions:**
1. âœ… Check directory exists: `ls ~/.cmdai-terminal/conversations/`
2. âœ… Verify write permissions: `touch ~/.cmdai-terminal/test`
3. âœ… Use proper home expansion in config (`~/.cmdai-terminal/...`)

### ğŸ”´ Streaming not working

**Symptoms:** Messages appear all at once instead of token-by-token

**Solutions:**
1. âœ… Verify API supports streaming responses
2. âœ… Check network isn't buffering responses
3. âœ… Ensure `stream: true` in API request

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:

- ğŸ› Report bugs
- ğŸ’¡ Suggest features
- ğŸ”§ Submit pull requests
- ğŸ“– Improve documentation

---

## ğŸ“„ License

MIT License - Feel free to use this project however you'd like!

---

## â­ Show Your Support

If you find cmdAI Terminal useful, please consider:
- â­ Starring the repository
- ğŸ› Reporting bugs
- ğŸ’¡ Suggesting new features
- ğŸ“¢ Sharing with others



